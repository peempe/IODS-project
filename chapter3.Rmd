# Logistic regression

### Reading the data

```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", 
                  sep = ",", header = T)
View(alc)
colnames(alc)
```

*The dataset is jointed from two different datasets and it includes information about students' alcohol consumpiton. The infromation is gathered from Portuguese and Math classes from two Portuguese schools*

*More information about the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Student+Performance).*


### The research plan and hypotheses

The aim of this week is to analyze the relationship of high/low alcohol consumption (AC) and following variables: mother's education (Medu), quality of family realtionships (famrel), current health status (health), and number of school absences (absences).

**My hypotheses are:**
1. Mother's low education is associated with higher AC.
2. Poor quality of family relationships is associated with higher AC.
3. Poor health status is associated with higher AC.
4. Higher number of school absences is associated with higher AC.


### Preliminary analyses

```{r}
library(ggplot2)
```

**Mother's education**
```{r}
Medutable <- table(alc$Medu,alc$high_use)
Medutable
```

**Quality of family relationships**
```{r}
FamRtable <- table(alc$famrel,alc$high_use)
FamRtable
```

**Current health status**
```{r}
Healthtable <- table(alc$health,alc$high_use)
Healthtable
```

**Number of school absences**
```{r}
g1 <- ggplot(alc, aes(x = high_use, y = absences, col = sex))
g1 + geom_boxplot() + ggtitle("School absences by alcohol consumption")
```


### Logistic regression

```{r}
m <- glm(high_use ~ Medu + famrel + health + absences, data = alc, family = "binomial")
summary(m)
# computing odds ratios (OR)
OR <- coef(m) %>% exp

# computing confidence intervals (CI)
CI <- confint(m) %>% exp

# printing out the odds ratios with their confidence intervals
cbind(OR, CI)
```


### Predictive power of the model

```{r}
# predicting the probability of high_use
probabilities <- predict(m, type = "response")

# adding the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# using the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# seeing the last ten original classes, predicted probabilities, and class predictions
select(alc, failures, absences, sex, high_use, probability, prediction) %>% tail(10)

# tabulating the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)
```
```{r}
# access dplyr and ggplot2
library(dplyr); library(ggplot2)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))

# define the geom as points and draw the plot
g + geom_point()

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table() %>% addmargins()

# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
```


### 10-fold cross-validation

```{r}
# 10-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```

**Work in progress... :)**

